{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Лабораторная работа №1. <br> Метрические алгоритмы классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнила: Кузнецова Екатерина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tНа языке Python программно реализовать два метрических алгоритма классификации: Naive Bayes и K Nearest Neighbours\n",
    "2.\tСравнить работу реализованных алгоритмов с библиотечными из scikit-learn\n",
    "3.\tДля тренировки, теста и валидации использовать один из предложенных датасетов (либо найти самостоятельно и внести в таблицу)\n",
    "4.\tСформировать краткий отчет (постановка задачи, реализация, эксперимент с данными, полученные характеристики, вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Исходные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет: http://archive.ics.uci.edu/ml/datasets/Zoo<br>\n",
    "Предметная область: обитатели зоопарка\n",
    "\n",
    "\n",
    "Количество записей: 101<br>\n",
    "Количество атрибутов: 17\n",
    "\n",
    "\n",
    "Атрибуты:\n",
    "\n",
    "1. Название животного (строка, уникальный для каждого экземпляра)\n",
    "2. Наличие волос (логический тип)\n",
    "3. Наличие перьев (логический тип)\n",
    "4. Яйца (логический тип)\n",
    "5. Млекопитающий (логический тип)\n",
    "6. Умеет летать (логический тип)\n",
    "7. Водный (логический тип)\n",
    "8. Хищник (логический тип)\n",
    "9. Наличие зубов (логический тип) \n",
    "10. Наличие позвоночника (логический тип)\n",
    "11. Дышит воздухом (логический тип)\n",
    "12. Ядовитость (логический тип)\n",
    "13. Наличие плавников (логический тип)\n",
    "14. Количество ног (набор целочисленных значений: {0,2,4,5,6,8})\n",
    "15. Наличие хвоста (логический тип)\n",
    "16. Является домашним (логический тип)\n",
    "17. Catsize (логический тип)\n",
    "18. Тип (целочисленные значения в диапазоне [1,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ход работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Реализация алгоритма Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# загрузка датасета\n",
    "def load_data(filename):\n",
    "    return pd.read_csv(filename, header=None).values\n",
    "\n",
    "# разделение датасета на тестовую и обучающую выборку\n",
    "def split_dataset(test_size):\n",
    "    dataset = load_data('zoo.data.csv')\n",
    "    animal_attr = dataset[:, 1:-1]\n",
    "    animal_class = dataset[:, -1]\n",
    "    animal_class = animal_class.astype(np.int64, copy=False)\n",
    "    data_train, data_test, class_train, class_test = train_test_split(animal_attr, animal_class,\n test_size=test_size, random_state=55)\n",
    "    return data_train, class_train, data_test, class_test\n",
    "\n",
    "\n",
    "# Разделяет обучающую выборку по классам таким образом, чтобы можно было получить все элементы, принадлежащие\n",
    "# определенному классу.\n",
    "def separate_by_class(data_train, class_train):\n",
    "    classes_dict = {}\n",
    "    for i in range(len(data_train)):\n",
    "        classes_dict.setdefault(class_train[i], []).append(data_train[i])\n",
    "    return classes_dict\n",
    "\n",
    "\n",
    "# инструменты для обобщения данных\n",
    "def mean(numbers):  # Среднее значение\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "\n",
    "def stand_dev(numbers):  # вычисление дисперсии\n",
    "    var = sum([pow(x - mean(numbers), 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(var)\n",
    "\n",
    "\n",
    "def summarize(data_train):  # обобщение данных\n",
    "    # Среднее значение и среднеквадратичное отклонение для каждого атрибута\n",
    "    summaries = [(mean(att_numbers), stand_dev(att_numbers)) for att_numbers in zip(*data_train)]\n",
    "    return summaries\n",
    "\n",
    "\n",
    "# Обучение классификатора\n",
    "def summarize_by_class(data_train, class_train):\n",
    "    # Разделяет обучающую выборку по классам таким образом, чтобы можно было получить все элементы, принадлежащие определенному классу.\n",
    "    classes_dict = separate_by_class(data_train, class_train)\n",
    "    summaries = {}\n",
    "    for class_name, instances in classes_dict.items():\n",
    "        # Среднее значение и среднеквадратичное отклонение атрибутов для каждого класса входных данных\n",
    "        summaries[class_name] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "\n",
    "# вычисление апостериорной вероятности принадлежности объекта к определенному классу\n",
    "def calc_probability(x, mean, stdev):\n",
    "    if stdev == 0:\n",
    "        stdev += 0.000001  # добавляем эпсилон, если дисперсия равна 0\n",
    "    exponent = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "\n",
    "# вычисление вероятности принадлежности объекта к каждому из классов\n",
    "def calc_class_probabilities(summaries, instance_attr):\n",
    "    probabilities = {}\n",
    "    for class_name, class_summaries in summaries.items():\n",
    "        probabilities[class_name] = 1.0\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev = class_summaries[i]\n",
    "            x = float(instance_attr[i])\n",
    "            probabilities[class_name] *= calc_probability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "# классификация одного объекта\n",
    "def predict_one(summaries, instance_attr):\n",
    "    # вычисление вероятности принадлежности объекта к каждому из классов\n",
    "    probabilities = calc_class_probabilities(summaries, instance_attr)\n",
    "    best_class, max_prob = None, -1\n",
    "    for class_name, probability in probabilities.items():\n",
    "        if best_class is None or probability > max_prob:\n",
    "            max_prob = probability\n",
    "            best_class = class_name\n",
    "    return best_class\n",
    "\n",
    "\n",
    "# классификация тестовой выборки\n",
    "def predict(summaries, data_test):\n",
    "    predictions = []\n",
    "    for i in range(len(data_test)):\n",
    "        result = predict_one(summaries, data_test[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# сравнение результатов классификации с реальными, вычисление точности классификации\n",
    "def calc_accuracy(summaries, data_test, class_test):\n",
    "    correct_answ = 0\n",
    "    # классификация тестовой выборки\n",
    "    predictions = predict(summaries, data_test)\n",
    "    for i in range(len(data_test)):\n",
    "        if class_test[i] == predictions[i]:\n",
    "            correct_answ += 1\n",
    "    return correct_answ / float(len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение работы реализованного алгоритма с библиотечным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNBClass  Accuracy:  0.9354838709677419\nsklNBClass  Accuracy:  0.967741935484\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_train, class_train, data_test, class_test = split_dataset(0.3)\n",
    "    summaries = summarize_by_class(data_train, class_train)\n",
    "    accuracy = calc_accuracy(summaries, data_test, class_test)\n",
    "    print('myNBClass ', 'Accuracy: ', accuracy)\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(data_train, class_train)\n",
    "    print('sklNBClass ', 'Accuracy: ', clf.score(data_test, class_test))\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Реализация алгоритма K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    dataset = pd.read_csv('zoo.data.csv', header=None).values\n",
    "    animal_attr = dataset[:, 1:-1]\n",
    "    animal_class = dataset[:, -1]\n",
    "    animal_class = animal_class.astype(np.int64, copy=False)\n",
    "    return train_test_split(animal_attr, animal_class, test_size=0.35)\n",
    "\n",
    "\n",
    "# евклидово расстояние от объекта №1 до объекта №2\n",
    "def euclidean_distance(instance1, instance2):\n",
    "    squares = [(i - j) ** 2 for i, j in zip(instance1, instance2)]\n",
    "    return sqrt(sum(squares))\n",
    "\n",
    "\n",
    "# рассчет расстояний до всех объектов в датасете\n",
    "def get_neighbours(instance, data_train, class_train, k):\n",
    "    distances = []\n",
    "    for i in data_train:\n",
    "        distances.append(euclidean_distance(instance, i))\n",
    "    distances = tuple(zip(distances, class_train))\n",
    "    # cортировка расстояний по возрастанию\n",
    "    # k ближайших соседей\n",
    "    return sorted(distances, key=operator.itemgetter(0))[:k]\n",
    "\n",
    "\n",
    "# определение самого распространенного класса среди соседей\n",
    "def get_response(neigbours):\n",
    "    return Counter(neigbours).most_common()[0][0][1]\n",
    "\n",
    "\n",
    "# классификация тестовой выборки\n",
    "def get_predictions(data_train, class_train, data_test, k):\n",
    "    predictions = []\n",
    "    for i in data_test:\n",
    "        neigbours = get_neighbours(i, data_train, class_train, k)\n",
    "        response = get_response(neigbours)\n",
    "        predictions.append(response)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# измерение точности\n",
    "def get_accuracy(data_train, class_train, data_test, class_test, k):\n",
    "    predictions = get_predictions(data_train, class_train, data_test, k)\n",
    "    mean = [i == j for i, j in zip(class_test, predictions)]\n",
    "    return sum(mean) / len(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение работы реализованного алгоритма с библиотечным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myKNClass Accuracy:  0.75\nsklKNClas Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_train, data_test, class_train, class_test = load_data()\n",
    "    print('myKNClass', 'Accuracy: ', get_accuracy(data_train, class_train, data_test, class_test, 15))\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=15)\n",
    "    clf.fit(data_train, class_train)\n",
    "    print('sklKNClas', 'Accuracy: ', clf.score(data_test, class_test))\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе лабораторной работы на языке Python были программно реализованы два метрических алгоритма классификации: Naive Bayes и K Nearest Neighbours. Для оценки точности классификации и сравнения полученных алгоритмов с аналогичными, реализованными в библиотеке scikit-learn, они были применены к датасету \"Зоопарк\".<br> Результаты тестирования показали, что библиотечная реализация Наивного Байесовского классификатора работает немного лучше, нежели воплощенная в данной лабораторной работе, но обе они показывают неплохие результаты классификации (более 93% правильно классифицированных объектов).<br> Обе реализации метода K ближайших соседей работают с одинаковой точностью (75%), но значитально проигрывают по качеству классификации Байесовскому алгоритму."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
