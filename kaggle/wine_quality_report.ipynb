{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Курсовая работа <br> Прогнозирование качества вина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнила: Кузнецова Екатерина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Цель работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить практические навыки работы с различными методами машинного обучения с использованием языка программирования python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выбрать соревнование на сайте kaggle.com.\n",
    "2. Прочитать описание задачи и скачать приложенные к заданию датасеты.\n",
    "3. С успехом выполнить выбранную задачу.\n",
    "4. Отправить данные на kaggle.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исходные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На kaggle.com размещено несколько сотен интереснейших соревнований, касающихся различных сфер жизни человека. Некоторые из них доступны только ограниченному кругу лиц, а в остальных может поучаствовать любой желающий. К последним относится и выбранная мною задача, \"Aalto Wine Quality Prediction\". Её авторы задались целью узнать, что делает вино хорошим. То есть какие показатели определяют качество этого благородного (или не очень) напитка.\n",
    "\n",
    "Соревнование: https://inclass.kaggle.com/c/aalto-wine-quality-prediction-t-61-3050-challenge<br>\n",
    "Предметная область: качественные характеристики вин<br>\n",
    "Задача: научиться прогнозировать качество вин без рейтинга экспертов\n",
    "\n",
    "К заданию было приложено 3 файла:\n",
    "\n",
    "- training_classification_regression_2015.csv (тренировочный набор данных)\n",
    "- challenge_public_test_classification_regression.csv (тестовый набор данных)\n",
    "- challenge_regression_sample_submission.csv (формат представления ответа)\n",
    "\n",
    "В каждом файле содержатся наименования атрибутов и их значения.\n",
    "\n",
    "#### Тренировочный датасет:\n",
    "\n",
    "Количество записей: 5000<br>\n",
    "Количество атрибутов: 13\n",
    "\n",
    "\n",
    "Атрибуты:\n",
    "\n",
    "1. fixedAcidity (float)\n",
    "2. volatileAcidity (float)\n",
    "3. citricAcid (float)\n",
    "4. residualSugar (float)\n",
    "5. chlorides (float)\n",
    "6. freeSulfurDioxide (float)\n",
    "7. totalSulfurDioxide (float)\n",
    "8. density (float)\n",
    "9. pH (float)\n",
    "10. alcohol (float)\n",
    "11. quality (целочисленные значения в диапазоне [1,7])\n",
    "12. type (строковое значение из набора {'Red', 'White'})\n",
    "\n",
    "#### Тестовый датасет:\n",
    "\n",
    "Количество записей: 1000<br>\n",
    "Количество атрибутов: 14\n",
    "\n",
    "Тестовый датасет содержит также поле id (int)\n",
    "\n",
    "#### Формат представления ответа:\n",
    "\n",
    "Атрибуты:\n",
    "\n",
    "1. id (int)\n",
    "2. quality (целочисленные значения в диапазоне [1,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ход работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Загрузка и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем обучающий набор данных. Как мы видим, в нём нет пропущенных значений, почти все значения относятся к вещественному типу (значит нормализация этих данных не будет лишней)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixedAcidity  volatileAcidity  citricAcid  residualSugar  chlorides  \\\n0      6.945513         0.272992    0.403691      13.920038   0.051043   \n1      6.995486         0.190402    0.310377      19.186267   0.044147   \n2      5.978831         0.140616    0.251393       4.402912   0.028109   \n3      6.688603         0.371501    0.507942      11.862843   0.044918   \n4      7.224421         0.201252    0.220918       1.612570   0.044984   \n5     13.386383         0.460975    0.518178       2.115102   0.071775   \n6      7.065214         0.541150    0.090961       2.028085   0.082078   \n\n   freeSulfurDioxide  totalSulfurDioxide   density        pH  sulphates  \\\n0          66.077662          245.612070  0.998768  3.161269   0.579738   \n1          39.852796          175.908433  1.000245  2.932994   0.523323   \n2          32.093612          151.569367  0.995412  3.488070   0.511582   \n3          67.531739          155.608503  0.998803  3.174425   0.439773   \n4          16.817987          121.629623  0.995424  3.373870   0.528637   \n5          12.244441           29.830350  1.002141  3.079549   0.560804   \n6           9.636658           16.456076  0.996450  3.430479   0.589915   \n\n     alcohol  quality   type  \n0   9.504513        4  White  \n1   9.112224        3  White  \n2  11.077951        4  White  \n3   8.853944        5  White  \n4  10.366208        5  White  \n5   8.985118        4    Red  \n6  11.637736        4    Red  \nКоличество записей в тренировочном датасете: 5000, количество атрибутов: 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('alc/training_classification_regression_2015.csv', header=0)\n",
    "print(train_df[:7])\n",
    "print('Количество записей в тренировочном датасете: %d, количество атрибутов: %d' % train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим теперь, что содержится в тестовой выборке. Среди значений основных атрибутов также нет пропусков, но для всех позиций не определены параметры \"качество\" и \"тип\" вина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  fixedAcidity  volatileAcidity  citricAcid  residualSugar  chlorides  \\\n0   1      6.623879         0.350308    0.291192      14.231505   0.044939   \n1   2      7.001997         0.360802    0.251197       5.802122   0.016012   \n2   3      8.365224         0.199237    0.313605       2.790155   0.054998   \n3   4      7.206049         0.262821    0.300107       9.007575   0.051003   \n4   5      6.915703         0.338247    0.735664      11.227664   0.069907   \n5   6      8.444906         0.563366    0.081195       2.098270   0.106025   \n6   7      7.873634         0.220525    0.419400      14.503407   0.044964   \n\n   freeSulfurDioxide  totalSulfurDioxide   density        pH  sulphates  \\\n0          56.313779          173.311310  1.000947  3.184398   0.579831   \n1          14.184137           66.170046  0.990834  2.847829   0.593433   \n2          16.875336           83.105477  0.994815  2.959980   0.451726   \n3          33.906743          169.741299  0.996002  3.217775   0.496368   \n4          45.824847          143.626491  0.997954  3.015690   0.811228   \n5          15.240263           44.276638  0.995852  3.155856   0.521046   \n6          45.720723          139.733768  1.001596  3.204271   0.688871   \n\n     alcohol  quality  type  \n0   9.107156      NaN   NaN  \n1  13.064054      NaN   NaN  \n2   9.570900      NaN   NaN  \n3  10.519251      NaN   NaN  \n4   9.388134      NaN   NaN  \n5  10.939845      NaN   NaN  \n6   8.575815      NaN   NaN  \nКоличество записей в тестовом датасете: 1000, количество атрибутов: 14\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('alc/challenge_public_test_classification_regression_2015.csv', header=0)\n",
    "print(test_df[:7])\n",
    "print('Количество записей в тестовом датасете: %d, количество атрибутов: %d' % test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в тестовой выборке не указан тип вина, следовательно для определения качества напитка он не так важен. Поэтому уберем этот параметр из обеих выборок.\n",
    "Также уберем из тестовой выборки поля \"id\" и \"quality\", которое нужно предсказать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиение обучающего датасета на значения атрибутов и массив классов\n",
    "train_wine_attr = train_df.drop(['quality', 'type'], axis=1).values\n",
    "train_wine_quality = train_df['quality'].astype(int).values\n",
    "\n",
    "test_wine_attr = test_df.drop(['id', 'quality', 'type'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуем вещественные атрибуты для их более удобной классификации и сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_wine_attr)\n",
    "train_wine_attr = scaler.transform(train_wine_attr)\n",
    "test_wine_attr = scaler.transform(test_wine_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге мы получем функции, которые загружают и подготавливают обучающие и тестовые данные для их дальнейшей классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    train_df = pd.read_csv('training_classification_regression_2015.csv', header=0)\n",
    "    # print('Количество записей в тренировочном датасете: %d, количество атрибутов: %d' % train_df.shape)\n",
    "\n",
    "    # разбиение обучающего датасета на значения атрибутов и массив классов\n",
    "    train_wine_attr = train_df.drop(['quality', 'type'], axis=1).values\n",
    "    train_wine_quality = train_df['quality'].astype(int).values\n",
    "\n",
    "    # нормализация значений атрибутов\n",
    "    scaler = preprocessing.StandardScaler().fit(train_wine_attr)\n",
    "    train_wine_attr = scaler.transform(train_wine_attr)\n",
    "\n",
    "    return train_wine_attr, train_wine_quality, scaler\n",
    "\n",
    "\n",
    "def load_test_data(scaler):\n",
    "    test_df = pd.read_csv('challenge_public_test_classification_regression_2015.csv', header=0)\n",
    "    # print('Количество записей в тестовом датасете: %d, количество атрибутов: %d' % test_df.shape)\n",
    "\n",
    "    # удаление ненужных атрибутов тестового массива\n",
    "    test_wine_attr = test_df.drop(['id', 'quality', 'type'], axis=1).values\n",
    "\n",
    "    # нормализация значений атрибутов\n",
    "    test_wine_attr = scaler.transform(test_wine_attr)\n",
    "\n",
    "    return test_wine_attr, test_df['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Подбор классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как множество значений атрибута \"качество\" конечно и имеет 7 целочисленных значений, следовательно мы решаем задачу классификации. Для обработки полученных данных и предсказания оценки качества каждого напитка из списка, необходимо выбрать подходящую модель классификатора. В ходе выполнения лабораторных работ было выявлено, что собственноручно реализованные алгоритмы работаю несколько хуже, нежели аналогичные методы, содержащиеся в библиотеке scikit learn. Поэтому было принято решение использовать для классификации библиотечную реализацию алгоритма. В scikit learn содержится более 20 моделей классификаторов, работающих с разной степенью точности. Для достижения оптимальных результатов, протестируем несколько моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В работе сравниваются следующие классификаторы:\n",
    "\n",
    "- DummyClassifier\n",
    "- AdaBoostClassifier\n",
    "- BaggingClassifier\n",
    "- ExtraTreesClassifier\n",
    "- GradientBoostingClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression\n",
    "- PassiveAggressiveClassifier\n",
    "- RidgeClassifier\n",
    "- SGDClassifier\n",
    "- GaussianNB\n",
    "- KNeighborsClassifier\n",
    "- NearestCentroid\n",
    "- MLPClassifier\n",
    "- LabelPropagation\n",
    "- SVC\n",
    "- LinearSVC\n",
    "- DecisionTreeClassifier\n",
    "- ExtraTreeClassifier\n",
    "\n",
    "Используем каждый из алгоритмов на наших данных и выберем те, которые классифицируют тренировочный датасет лучше. Для более точных результатов будем использовать кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: DummyClassifier(constant=None, random_state=None, strategy='stratified').\n  Точность: 0.33400 (0.04285)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n          learning_rate=1.0, n_estimators=50, random_state=None).\n  Точность: 0.24140 (0.08530)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: BaggingClassifier(base_estimator=None, bootstrap=True,\n         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n         verbose=0, warm_start=False).\n  Точность: 0.59220 (0.04415)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n           max_depth=None, max_features='auto', max_leaf_nodes=None,\n           min_impurity_split=1e-07, min_samples_leaf=1,\n           min_samples_split=2, min_weight_fraction_leaf=0.0,\n           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n           verbose=0, warm_start=False).\n  Точность: 0.62800 (0.04972)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=3,\n              max_features=None, max_leaf_nodes=None,\n              min_impurity_split=1e-07, min_samples_leaf=1,\n              min_samples_split=2, min_weight_fraction_leaf=0.0,\n              n_estimators=100, presort='auto', random_state=None,\n              subsample=1.0, verbose=0, warm_start=False).\n  Точность: 0.56480 (0.05262)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_split=1e-07, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n            verbose=0, warm_start=False).\n  Точность: 0.59920 (0.04935)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False).\n  Точность: 0.53880 (0.04828)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n              loss='hinge', n_iter=5, n_jobs=1, random_state=None,\n              shuffle=True, verbose=0, warm_start=False).\n  Точность: 0.39800 (0.06567)\nМетод классификации: RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n        max_iter=None, normalize=False, random_state=None, solver='auto',\n        tol=0.001).\n  Точность: 0.52580 (0.05181)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n       verbose=0, warm_start=False).\n  Точность: 0.44160 (0.05658)\nМетод классификации: GaussianNB(priors=None).\n  Точность: 0.44700 (0.05536)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform').\n  Точность: 0.56340 (0.04246)\nМетод классификации: NearestCentroid(metric='euclidean', shrink_threshold=None).\n  Точность: 0.23540 (0.04114)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(100,), learning_rate='constant',\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\n       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n       verbose=False, warm_start=False).\n  Точность: 0.56480 (0.05636)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: LabelPropagation(alpha=1, gamma=20, kernel='rbf', max_iter=30, n_jobs=1,\n         n_neighbors=7, tol=0.001).\n  Точность: 0.63100 (0.05255)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False).\n  Точность: 0.57180 (0.04629)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0).\n  Точность: 0.52840 (0.04917)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_split=1e-07, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best').\n  Точность: 0.52860 (0.06416)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод классификации: ExtraTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n          max_features='auto', max_leaf_nodes=None,\n          min_impurity_split=1e-07, min_samples_leaf=1,\n          min_samples_split=2, min_weight_fraction_leaf=0.0,\n          random_state=None, splitter='random').\n  Точность: 0.50520 (0.04267)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def test_class_models(train_wine_attr, train_wine_quality):\n",
    "    class_models = [DummyClassifier(), AdaBoostClassifier(), BaggingClassifier(), ExtraTreesClassifier(),\n",
    "                    GradientBoostingClassifier(), RandomForestClassifier(), LogisticRegression(),\n",
    "                    PassiveAggressiveClassifier(), RidgeClassifier(), SGDClassifier(), GaussianNB(),\n",
    "                    KNeighborsClassifier(), NearestCentroid(), MLPClassifier(),\n",
    "                    LabelPropagation(), SVC(), LinearSVC(), DecisionTreeClassifier(),\n",
    "                    ExtraTreeClassifier()]\n",
    "\n",
    "    for clf in class_models:\n",
    "        result = cross_val_score(clf, train_wine_attr, train_wine_quality, cv=KFold(n_splits=50))\n",
    "        print('Метод классификации: {}.\\n  Точность: {:.5f} ({:.5f})'.format(clf, \n",
    "                                                                             result.mean(), \n",
    "                                                                             result.std()))\n",
    "        \n",
    "test_class_models(train_wine_attr, train_wine_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая высокая точность классификации получилась при использовании методов RandomForestClassifier, ExtraTreesClassifier и LabelPropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как классификаторы запускались без параметров, то есть шанс улучшить показатели точности путем подбора наиболее удачных значений для атрибутов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследование параметров LabelPropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование LabelPropagation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность без параметров: 0.62540 (0.02702)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = knn, n_neighbors = 10 0.495 0.0257021399887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = knn, n_neighbors = 20 0.4762 0.0295154196989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = knn, n_neighbors = 30 0.4776 0.0321347164294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = knn, n_neighbors = 50 0.4716 0.0332722106269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = knn, n_neighbors = 60 0.4588 0.025926048677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = rbf 0.6254 0.0270192523953\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 0.1 0.4382 0.0378940628595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 0.5 0.4392 0.037578717381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 1 0.4672 0.0318144621202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 5 0.6144 0.0248644324287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 10 0.6204 0.0283661770424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 20 0.6254 0.0270192523953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 30 0.6238 0.0274947267671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 40 0.6234 0.0271079324184\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.01 0.624 0.0281424945589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.1 0.624 0.0281424945589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.5 0.624 0.0281424945589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1 0.6254 0.0270192523953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 2 0.6236 0.0282814426789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 3 0.6238 0.0282127630692\n--------------\n"
     ]
    }
   ],
   "source": [
    "def test_LabelPropagation(train_wine_attr, train_wine_quality):\n",
    "    print('Тестирование LabelPropagation')\n",
    "\n",
    "    # Без параметров\n",
    "    result = cross_val_score(LabelPropagation(), train_wine_attr, train_wine_quality, cv=KFold(n_splits=20))\n",
    "    print('Точность без параметров: {:.5f} ({:.5f})'.format(result.mean(), result.std()))\n",
    "\n",
    "    # Функция ядра\n",
    "    # knn\n",
    "    for i in [10, 20, 30, 50, 60]:\n",
    "        res = cross_val_score(LabelPropagation(kernel='knn', n_neighbors=i), \n",
    "                              train_wine_attr, train_wine_quality,\n",
    "                              cv=KFold(n_splits=20))\n",
    "        print('kernel = knn, n_neighbors =', i, res.mean(), res.std())\n",
    "    # rbf\n",
    "    res = cross_val_score(LabelPropagation(kernel='rbf'), \n",
    "                          train_wine_attr, train_wine_quality,\n",
    "                          cv=KFold(n_splits=20))\n",
    "    print('kernel = rbf', res.mean(), res.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Параметр для rbf ядра\n",
    "    gammas = [0.1, 0.5, 1, 5, 10, 20, 30, 40]\n",
    "    for gamma in gammas:\n",
    "        res = cross_val_score(LabelPropagation(kernel='rbf', gamma=gamma), \n",
    "                              train_wine_attr, train_wine_quality,\n",
    "                              cv=KFold(n_splits=20))\n",
    "        print('gamma =', gamma, res.mean(), res.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Параметр для rbf ядра\n",
    "    alphas = [0.01, 0.1, 0.5, 1, 2, 3]\n",
    "    for alpha in alphas:\n",
    "        res = cross_val_score(LabelPropagation(alpha=alpha), \n",
    "                              train_wine_attr, train_wine_quality,\n",
    "                              cv=KFold(n_splits=20))\n",
    "        print('alpha =', alpha, res.mean(), res.std())\n",
    "    print('--------------')\n",
    "    \n",
    "test_LabelPropagation(train_wine_attr, train_wine_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследование параметров ExtraTreesClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование ExtraTreesClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность без параметров: 0.62360 (0.02629)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 0.625 0.0319718626295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 20 0.6536 0.0247030362506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 30 0.6596 0.0277964026449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 40 0.6698 0.0301589124472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 50 0.6604 0.0333682483808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 60 0.6616 0.0276665863453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 70 0.6676 0.0274488615429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 80 0.666 0.0321869538789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 90 0.665 0.0306169887481\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = gini 0.6162 0.0223239781401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = entropy 0.6262 0.0228901725638\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = auto 0.6234 0.0282354387251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = log2 0.62 0.0218357505023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 1 0.6204 0.0177493661859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 3 0.631 0.0299833287011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 5 0.6208 0.0274401166178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 7 0.622 0.0278136657059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 9 0.6242 0.029650632371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 11 0.6256 0.026027677576\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_start = True 0.6272 0.0225424044858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_start = False 0.6288 0.0324863048068\n--------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def test_ExtraTreesClassifier(train_wine_attr, train_wine_quality):\n",
    "    print('Тестирование ExtraTreesClassifier')\n",
    "\n",
    "    # Без параметров\n",
    "    result = cross_val_score(ExtraTreesClassifier(), train_wine_attr, train_wine_quality, cv=KFold(n_splits=20))\n",
    "    print('Точность без параметров: {:.5f} ({:.5f})'.format(result.mean(), result.std()))\n",
    "\n",
    "    # Количество деревьев (default=10)\n",
    "    n_estimators = np.arange(10, 100, 10)\n",
    "    for n_estimator in n_estimators:\n",
    "        result = cross_val_score(ExtraTreesClassifier(n_estimators=n_estimator), train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('n_estimators =', n_estimator, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Функция оценки качества разбиения (default=”gini”)\n",
    "    criterion = ['gini', 'entropy']\n",
    "    for cr in criterion:\n",
    "        result = cross_val_score(ExtraTreesClassifier(criterion=cr), \n",
    "                                 train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('criterion =', cr, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Количество фич при поиске наилучшего разбиения (default=”auto”)\n",
    "    max_features = ['auto', 'log2', 1, 3, 5, 7, 9, 11]\n",
    "    for features in max_features:\n",
    "        result = cross_val_score(ExtraTreesClassifier(max_features=features), \n",
    "                                 train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('max_features =', features, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Использовать ли предыдушие решения? (default=False)\n",
    "    warm_start = [True, False]\n",
    "    for war_start in warm_start:\n",
    "        result = cross_val_score(ExtraTreesClassifier(warm_start=war_start), \n",
    "                                 train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('warm_start =', war_start, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "    \n",
    "test_ExtraTreesClassifier(train_wine_attr, train_wine_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследование параметров RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование RandomForestClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность без параметров: 0.59960 (0.02491)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 60 0.6442 0.0275818781086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 80 0.6388 0.0284843816854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 100 0.6474 0.0335922610135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 120 0.6484 0.0321968942602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 140 0.6494 0.0354462974089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 160 0.6516 0.0328609190377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 180 0.648 0.0368347661863\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = gini 0.5978 0.0302119181781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = entropy 0.5982 0.031457272609\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = auto 0.6022 0.0316600694882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = log2 0.59 0.0302654919008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 1 0.5938 0.0321863325031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 3 0.6086 0.028263757712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 5 0.6056 0.0343953485227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 7 0.597 0.0262259413558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 9 0.5976 0.0344185996229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 11 0.5926 0.0231266080522\n--------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_start = True 0.5974 0.028207091307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_start = False 0.5908 0.018508376482\n--------------\n"
     ]
    }
   ],
   "source": [
    "def test_RandomForestClassifier(train_wine_attr, train_wine_quality):\n",
    "    print('Тестирование RandomForestClassifier')\n",
    "\n",
    "    # Без параметров\n",
    "    result = cross_val_score(RandomForestClassifier(), \n",
    "                             train_wine_attr, train_wine_quality, \n",
    "                             cv=KFold(n_splits=20))\n",
    "    print('Точность без параметров: {:.5f} ({:.5f})'.format(result.mean(), result.std()))\n",
    "\n",
    "    # Количество деревьев (default=10)\n",
    "    n_estimators = np.arange(60, 200, 20)\n",
    "    for n_estimator in n_estimators:\n",
    "        result = cross_val_score(RandomForestClassifier(n_estimators=n_estimator), \n",
    "                                 train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('n_estimators =', n_estimator, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Функция оценки качества разбиения (default=”gini”)\n",
    "    criterions = ['gini', 'entropy']\n",
    "    for criterion in criterions:\n",
    "        result = cross_val_score(RandomForestClassifier(criterion=criterion), \n",
    "                                 train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('criterion =', criterion, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Количество фич при поиске наилучшего разбиения (default=”auto”)\n",
    "    max_features = ['auto', 'log2', 1, 3, 5, 7, 9, 11]\n",
    "    for features in max_features:\n",
    "        result = cross_val_score(RandomForestClassifier(max_features=features), \n",
    "                                 train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('max_features =', features, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "\n",
    "    # Использовать ли предыдушие решения? (default=False)\n",
    "    warm_start = [True, False]\n",
    "    for war_start in warm_start:\n",
    "        result = cross_val_score(RandomForestClassifier(warm_start=war_start), \n",
    "                                 train_wine_attr, train_wine_quality,\n",
    "                                 cv=KFold(n_splits=20))\n",
    "        print('warm_start =', war_start, result.mean(), result.std())\n",
    "    print('--------------')\n",
    "    \n",
    "test_RandomForestClassifier(train_wine_attr, train_wine_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение некоторых параметров классификаторов существенно увеличило точность определения качества. Определим оптимальный набор параметров каждого классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод ExtraTreesClassifier показал лучшие результаты классификации. Используем его для решения нашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод ExtraTreesClassifier показал лучшие результаты классификации. Используем его для решения нашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Решение задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи нужно обучить выбранный классификатор и применить его к тестовой выборке. Результат будем выводить в файл в формате \"id, quality\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_wine_attr, train_wine_quality, s = load_train_data()\n",
    "    test_wine_attr, id = load_test_data(s)\n",
    "\n",
    "    clf = ExtraTreesClassifier(n_estimators=50, criterion='entropy', max_features='log2', warm_start=True)\n",
    "    clf.fit(train_wine_attr, train_wine_quality)\n",
    "    result = clf.predict(test_wine_attr)\n",
    "\n",
    "    # Создание выходного файла\n",
    "    output = pd.DataFrame(id)\n",
    "    output['quality'] = result\n",
    "    output.to_csv('submission.csv', index=False)\n",
    "    \n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения работы была решена задача определения качества вина на основании только качественных характеристик напитка (без использования экспертных оценок). Для этого мы скачали и проанализировали данные с сайта kaggle.com, затем применили к нему наиболее точный алгоритм классификации из библиотеки scikit learn. Модель ExtraTreesClassifier показала самые высокие результаты на обучающей выборке. Результат классификации тестового датасета был сформирован в указанном в задании формате. Проверить точность классификации не удалось, так как выбранное соревнование относится к завершенным и ответы не принимаются."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}